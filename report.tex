% Template for ICIP-2018 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{url,spconf,amsmath,graphicx,spverbatim}
%\usepackage[section]{placeins}
% \usepackage[subsection]{placeins}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{float}
\lstset{
  basicstyle=\ttfamily,
  columns=fullflexible,
  frame=single,
  breaklines=true,
  keepspaces=true,
  postbreak=\mbox{\textcolor{}{$\hookrightarrow$}\space},
}

% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}

% Title.
% ------
\title{Machine Learning Assignment-2}
%
% Single address.
% ---------------
\name{M.Arun kumar}
\address{173079004}
%
%
\begin{document}
%\ninept
%
\maketitle
%
\begin{abstract}
  To use different models to predict the attrition of the employees. In this Assignment i have used some of the preprocessing of the data and then applied the preprocessed data to different machine learning models. Some of the models i tried are Linear Regression, Random Forest, SVM and a simple sequential neural network with single hidden layer. While kernalised SVM gave the highest score on the Kaggle Leaderboard the code present in the `other\_models.py`. The code file is enclosed seperately along with this report, It also includes Linear Regression and SVM. The code for Neural network is present in this report.
\end{abstract}

\section{Preprocessing}
\label{sec:intro}
The data contains information about employees work pattern, work type, satisfaction levels etc., Information about 1028 employees and 34 types of data is given which contains both text and numbers. 

\begin{figure}[h]\label{column_names}
  \includegraphics[width=\linewidth]{column_names}
  \caption{Columns present in the Data} 
\end{figure}

Fig~\ref{column_names} shows the list of columns present in the training data.Even though there are different Machine Learning approachs like NLP and text recognition etc which mainly focus on transforming the text to vector space, so that the text can be represented using numbers, I used simple approaches to transform text to numbers because i could not find any relation between the words present in the text and most of the text is static (i.e, has same meaning in every occurance). Text is independent which allowed me to encode in an easy way.  

\begin{figure}\label{text_col}
  \includegraphics[width=\linewidth]{text_columns}
  \caption{Columns with text information present in the Data}
\end{figure}

Fig~\ref{text_col} shows the columns with text content which has to be transformed to numerical content appropriately. Along with these information there is data which is not relevant to the learning problem, so removing these columns will enhance the performance of the machine learning models. The columns which are not required are `EmployeeCount`, `EmployeeNumber`, `ID`. The columns removed serve the purpose of uniquely identifying the employee or might be used as simple indexing to sort the employees in either case it would'nt help the model in deciding whether the employee leaves the company or not.
"Gender" column is either "Male"  or "Female", So, 1,-1 are used to represent Gender. 0 can be used but if may values are 0 then gradient might get stuck in the neural network. Similary "OverTime" column is represented with 1,-1. Columns like Department, MaritalStatus, EducationField, JobRole etc are coded based on the different values they take with out any order of preference, it is assumed that the model will learn any of the heirarcy present ( if any).

\subsection{Scaling}
MinMaxScaling is sklearn library is used to scale the columns so that the data lies in $(0,1)$ range. This is usually required becaues the data contains the columns which are having high values which will explode when used in a neural network and the gradient calculation will also result in high values. Also the outliers (if any) present will have nominal impact in the decision making process.
\section{Approaches used}
\label{sec:pagestyle}
\subsection{Sequential Neural Network}
I wanted to try a simple neural network with single hidden layer, pytorch nn.sequential helped me in doing that. After preprocssing a sequential neural network model with linear input layer with ReLU activation function followed by a hidden linear layer with sigmoid activation is used. Hidden layer has 200 neurons the size of hidden layer is taken after trying out several other combinations with criteria being accuracy.
\subsubsection{Weights Initialisation}
Since weights to the model have to be randomly initialised prevent layer activation outputs from exploding or vanishing during the course of a forward pass through a deep neural network. If either occurs, loss gradients will either be too large or too small to flow backwards beneficially, and the network will take longer to converge, if it is even able to do so at all. So Xavier weight initialization is used to initialise weights as it  would maintain the variance of activations and back-propagated gradients all the way up or down the layers of a network. Even though it is not the suggested initialisation method for layers having ReLU activation function, because of asymmetry. Xavier is used for all layers, this might have reduced accuracy to some extent. 
\subsubsection{Loss Function}
A proper loss function is necessary in any neural network as it is used in weight updation. If loss function is not able to capture the heuristic of the learning problem then the loss might not converge and it will be difficult to get good accuracy. As we have a classification problem with 0 or 1 as the output Binary Cross Entropy is used as loss function. Adam optimiser with learning rate of 0.01 is used to find gradient and update weights is used. Learning rate of 0.01 is finalised after some trails.
\subsubsection{Training and testing}
Model is trained with trian data in batches of 32 for 500 epoches and the model with least training loss is saved and used for testing. Predictions are made with saved model after the testing data is preprocessed in the same way as the traing data. Accuracy of around $84\%$ is obtained.

\subsection{Logistic Regression}
Logistic Regression model from Sklearn library is used, A grid search for the hyper parameters tuning is performed and the best scoring( in terms of accuracy) hyper parameter set is used and the weights are updated based on the training and later test data is used to get the results. This model gave accuracy close to $75\%$. L2 norm is used as penality on weights for regularisation. 

\subsection{Random Forest}
Random Forest model from Sklearn library is used, A grid search for the hyper parameters tuning is performed and the best scoring( in terms of accuracy) hyper parameter set is used and the weights are updated based on the training and later test data is used to get the results. This model gave accuracy close to $88.88\%$\\

Predictions obtained after using these models are in format which is not accepted in kaggle. So a small bash script is used to format the output as required the code used is present below.


\subsection{SVM}
SVM model from Sklearn library is used, A grid search for the hyper parameters tuning is performed and the best scoring( in terms of accuracy) hyper parameter set is used and the weights are updated based on the training and later test data is used to get the results. This model gave accuracy close to $89.39\%$. "rbf" kernel is used as the decision boundary might be non-linear. 

\begin{spverbatim}
  cat file.csv | cut -d , -f 2| sed s/\.000000000000000000e+00//g | cut -d , -f 1 | sed s/000000000000000//g| cut -d , -f 1 | sed s/e+03//g| sed "s/\([0-9]\).\(...\)/\1\2/g" | cut -d\$'\n' -f 2,3 | sed "s/\([0-9]\)\([0-9]\)/\1 \2/g"| sed "s/\([0-9]\) \([0-9][0-9]\) \([0-9]\)/\1\2\3/g" 
\end{spverbatim}
\section{Conclusion}
Neural Network would have performed better if the hyper parameters were tuned properly. Time constraints restriced the tuning. In data preprocessing part i performed correlation between columns to weed out the redundant columns which was performed for training data. Implementing the same on testing data created problems. So, implementing this would have improved accuracy to some extent. Even though SVM performed well on this data, all other models performed relatively close to that of SVM. Much more preprocessing and little fine tuning of hyper parameters would have definitely helped in increasing the accuracy score.
\section{Git Hub Link}
    \url{https://github.com/M-ark17/MachineLearning/blob/master/other_models.py}
\label{sec:ref}



\end{description}
% \bibliography{strings,refs}
\onecolumn
\section{APPENDIX}
\subsection{Code for preprocessing and training network }
\lstinputlisting[language=Python]{EDA_assignment2.py}
\subsection{Code for predicting output for test data }
\lstinputlisting[language=Python]{nn_test.py}
\end{document}
